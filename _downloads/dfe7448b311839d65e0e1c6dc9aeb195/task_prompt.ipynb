{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Prompt Formatter\n\nThe formatter module in AgentScope is responsible for\n\n- converting messages into the expected format for different LLM APIs,\n- (optional) truncating messages to fit within token limits,\n- (optional) prompt engineering, e.g. summarizing long conversations.\n\nThe last two are optional and can also be handled by developers within the memory or at the agent level.\n\nIn AgentScope, there are two types of formatters, \"ChatFormatter\" and \"MultiAgentFormatter\", distinguished by the agent identities in their input messages.\n\n- **ChatFormatter**: Designed for standard user-assistant scenario (chatbot), using the ``role`` field to identify the user and assistant.\n- **MultiAgentFormatter**: Designed for multi-agent scenario, use the ``name`` field to identify different agents, which will combine conversation history into a single user message dictionary.\n\nThe built-in formatters are listed below\n\n.. list-table:: The built-in formatters in AgentScope\n    :header-rows: 1\n\n    * - API Provider\n      - User-assistant Scenario\n      - Multi-Agent Scenario\n    * - OpenAI\n      - ``OpenAIChatFormatter``\n      - ``OpenAIMultiAgentFormatter``\n    * - Anthropic\n      - ``AnthropicChatFormatter``\n      - ``AnthropicMultiAgentFormatter``\n    * - DashScope\n      - ``DashScopeChatFormatter``\n      - ``DashScopeMultiAgentFormatter``\n    * - Gemini\n      - ``GeminiChatFormatter``\n      - ``GeminiChatFormatter``\n    * - Ollama\n      - ``OllamaChatFormatter``\n      - ``OllamaMultiAgentFormatter``\n    * - DeedSeek\n      - ``DeepSeekChatFormatter``\n      - ``DeepSeekMultiAgentFormatter``\n    * - vLLM\n      - ``OpenAIChatFormatter``\n      - ``OpenAIMultiAgentFormatter``\n\n.. tip:: The OpenAI API supports the `name` field, so that `OpenAIChatFormatter` can also be used in multi-agent scenario. You can also use the `OpenAIMultiAgentFormatter` instead, which combine conversation history into a single user message.\n\nBesides, the built-in formatters support to convert different message blocks into the expected format for the target API, which are list below:\n\n.. list-table:: The supported message blocks in the built-in formatters\n    :header-rows: 1\n\n    * - Formatter\n      - tool_use/result\n      - image\n      - audio\n      - video\n      - thinking\n    * - ``OpenAIChatFormatter``\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u274c\n      -\n    * - ``DashScopeChatFormatter``\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u274c\n      -\n    * - ``DashScopeMultiAgentFormatter``\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u274c\n      -\n    * - ``AnthropicChatFormatter``\n      - \u2705\n      - \u2705\n      - \u274c\n      - \u274c\n      - \u2705\n    * - ``AnthropicMultiAgentFormatter``\n      - \u2705\n      - \u2705\n      - \u274c\n      - \u274c\n      - \u2705\n    * - ``GeminiChatFormatter``\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n      -\n    * - ``GeminiMultiAgentFormatter``\n      - \u2705\n      - \u2705\n      - \u2705\n      - \u2705\n      -\n    * - ``OllamaChatFormatter``\n      - \u2705\n      - \u2705\n      - \u274c\n      - \u274c\n      -\n    * - ``OllamaMultiAgentFormatter``\n      - \u2705\n      - \u2705\n      - \u274c\n      - \u274c\n      -\n    * - ``DeepSeekChatFormatter``\n      - \u2705\n      - \u274c\n      - \u274c\n      - \u274c\n      -\n    * - ``DeepSeekMultiAgentFormatter``\n      - \u2705\n      - \u274c\n      - \u274c\n      - \u274c\n      -\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>As stated in the [official documentation](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#preserving-thinking-blocks), only Anthropic suggests to preserve the thinking blocks in prompt formatting. For the others, we just ignore the thinking blocks in the input messages.</p></div>\n\n## ReAct-Oriented Formatting\nThe built-in formatters are all designed to support ReAct-style agents, where the input messages **consist of alternating conversation history and tool call sequences**.\n\nIn user-assistant scenario, the conversation history includes the user and assistant messages, we just convert them into the expected format directly.\nHowever, in multi-agent scenario, the conversation history is a list of messages from different agents as follows:\n\n.. figure:: ../../_static/images/multiagent_msgs.png\n    :alt: example of multiagent messages\n    :width: 85%\n    :align: center\n\n    *Example of multi-agent messages*\n\n\nTherefore, we have to merge the conversation history into a single user message with tags \"<history>\" and \"</history>\".\nTaking DashScope as an example, the formatted message will look like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.token import HuggingFaceTokenCounter\nfrom agentscope.formatter import DashScopeMultiAgentFormatter\nfrom agentscope.message import Msg, ToolResultBlock, ToolUseBlock, TextBlock\nimport asyncio, json\n\n\ninput_msgs = [\n    # System prompt\n    Msg(\"system\", \"You're a helpful assistant named Friday\", \"system\"),\n    # Conversation history\n    Msg(\"Bob\", \"Hi, Alice, do you know the nearest library?\", \"assistant\"),\n    Msg(\n        \"Alice\",\n        \"Sorry, I don't know. Do you have any idea, Charlie?\",\n        \"assistant\",\n    ),\n    Msg(\n        \"Charlie\",\n        \"No, let's ask Friday. Friday, get me the nearest library.\",\n        \"assistant\",\n    ),\n    # Tool sequence\n    Msg(\n        \"Friday\",\n        [\n            ToolUseBlock(\n                type=\"tool_use\",\n                name=\"get_current_location\",\n                id=\"1\",\n                input={},\n            ),\n        ],\n        \"assistant\",\n    ),\n    Msg(\n        \"system\",\n        [\n            ToolResultBlock(\n                type=\"tool_result\",\n                name=\"get_current_location\",\n                id=\"1\",\n                output=[TextBlock(type=\"text\", text=\"104.48, 36.30\")],\n            ),\n        ],\n        \"system\",\n    ),\n    Msg(\n        \"Friday\",\n        [\n            ToolUseBlock(\n                type=\"tool_use\",\n                name=\"search_around\",\n                id=\"2\",\n                input={\"location\": [104.48, 36.30], \"keyword\": \"library\"},\n            ),\n        ],\n        \"assistant\",\n    ),\n    Msg(\n        \"system\",\n        [\n            ToolResultBlock(\n                type=\"tool_result\",\n                name=\"search_around\",\n                id=\"2\",\n                output=[TextBlock(type=\"text\", text=\"[...]\")],\n            ),\n        ],\n        \"system\",\n    ),\n    # Conversation history continues\n    Msg(\"Friday\", \"The nearest library is ...\", \"assistant\"),\n    Msg(\"Bob\", \"Thanks, Friday!\", \"user\"),\n    Msg(\"Alice\", \"Let's go together.\", \"user\"),\n]\n\n\nasync def run_formatter_example() -> list[dict]:\n    \"\"\"Example of how to format multi-agent messages.\"\"\"\n    formatter = DashScopeMultiAgentFormatter()\n    formatted_message = await formatter.format(input_msgs)\n    print(\"The formatted message:\")\n    print(json.dumps(formatted_message, indent=4))\n    return formatted_message\n\n\nformatted_message = asyncio.run(run_formatter_example())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specifically, the conversation histories are formatted into:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"The first conversation history:\")\nprint(formatted_message[1][\"content\"])\n\nprint(\"\\nThe second conversation history:\")\nprint(formatted_message[-1][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Truncation-based Formatting\nWith the token module in AgentScope, the built-in formatters support to truncate the input messages by **deleting the oldest messages** (except the system prompt message) when the token exceeds the limit.\n\nTaking OpenAIFormatter as an example, we first calculate the total number of tokens of the input messages.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def run_token_counter() -> int:\n    \"\"\"Compute the token number of the input messages.\"\"\"\n    # We use huggingface token counter for dashscope models.\n    token_counter = HuggingFaceTokenCounter(\n        \"Qwen/Qwen2.5-VL-3B-Instruct\",\n        use_mirror=False,\n    )\n\n    return await token_counter.count(formatted_message)\n\n\nn_tokens = asyncio.run(run_token_counter())\nprint(\"The tokens in the formatted messages are: \", n_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we set the maximum token limit to 20 tokens less than the total number of tokens and run the formatter.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def run_truncated_formatter() -> None:\n    \"\"\"Example of how to format messages with truncation.\"\"\"\n    token_counter = HuggingFaceTokenCounter(\n        pretrained_model_name_or_path=\"Qwen/Qwen2.5-VL-3B-Instruct\",\n        use_mirror=False,\n    )\n    formatter = DashScopeMultiAgentFormatter(\n        token_counter=token_counter,\n        max_tokens=n_tokens - 20,\n    )\n    truncated_formatted_message = await formatter.format(input_msgs)\n    n_truncated_tokens = await token_counter.count(truncated_formatted_message)\n    print(\"The tokens after truncation: \", n_truncated_tokens)\n\n    print(\"\\nThe conversation history after truncation:\")\n    print(truncated_formatted_message[1][\"content\"])\n\n\nasyncio.run(run_truncated_formatter())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the first two messages from Bob and Alice are removed to fit within the context length limits.\n\n\n## Customizing Formatter\nAgentScope provides two base classes ``FormatterBase`` and its child class ``TruncatedFormatterBase``.\nThe ``TruncatedFormatterBase`` class provides the FIFO truncation strategy, and all the built-in formatters are inherited from it.\n\n.. list-table:: The base classes of formatters in AgentScope\n  :header-rows: 1\n\n  * - Class\n    - Abstract Method\n    - Description\n  * - ``FormatterBase``\n    - ``format``\n    - Format the input ``Msg`` objects into the expected format for the target API\n  * - ``TruncatedFormatterBase``\n    - ``_format_agent_message``\n    - Format the agent messages, which may contain multiple identities in multi-agent scenario\n  * -\n    - ``_format_tool_sequence``\n    - Format the tool use and result sequence into the expected format\n  * -\n    - ``_format`` (optional)\n    - Format the input ``Msg`` objects into the expected format for the target API\n\n.. tip:: - The ``_format`` in ``TruncatedFormatterBase`` groups input messages into agent messages and tool sequences, and then format them by calling ``_format_agent_message`` and ``_format_tool_sequence`` respectively. You can override it to implement your own formatting strategy.\n - Optionally, you can override the ``_truncate`` method in ``TruncatedFormatterBase`` to implement your own truncation strategy.\n\n## Further Reading\n\n- `token`\n- `model`\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}