# -*- coding: utf-8 -*-
"""Example: Using GraphKnowledgeBase with Neo4j.

This example demonstrates how to use the GraphKnowledgeBase with different
configurations and search modes.
"""

import asyncio
import os
import sys
from pathlib import Path

src_path = Path(__file__).parent.parent / "src"
sys.path.insert(0, str(src_path))

from agentscope.rag import (
    GraphKnowledgeBase,
    Neo4jGraphStore,
    Document,
    DocMetadata,
)
from agentscope.embedding import DashScopeTextEmbedding
from agentscope.model import DashScopeChatModel

# DashScope API Key
DASHSCOPE_API_KEY = "your api key"
os.environ["DASHSCOPE_API_KEY"] = DASHSCOPE_API_KEY

# Neo4j
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "password" 


async def example_basic_vector_only():
    """Example 1: Basic usage (vector-only, no graph features)."""
    print("\n" + "="*80)
    print("Example 1: Basic Vector-Only Mode (No Graph Features)")
    print("="*80)
    
    # Initialize Neo4j graph store
    graph_store = Neo4jGraphStore(
        uri=NEO4J_URI,
        user=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database="neo4j",
        collection_name="basic_knowledge",
        dimensions=1536,
    )
    
    # Initialize knowledge base (graph features disabled)
    knowledge = GraphKnowledgeBase(
        graph_store=graph_store,
        embedding_model=DashScopeTextEmbedding(
            model_name="text-embedding-v2",
            api_key=DASHSCOPE_API_KEY,
        ),
        llm_model=None,  # No LLM needed for vector-only mode
        enable_entity_extraction=False,
        enable_relationship_extraction=False,
        enable_community_detection=False,
    )
    
    # Create sample documents
    documents = [
        Document(
            id="doc1",
            metadata=DocMetadata(
                content={"type": "text", "text": "Alice works at OpenAI as a researcher specializing in language models."},
                doc_id="doc1",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc2",
            metadata=DocMetadata(
                content={"type": "text", "text": "OpenAI is located in San Francisco and develops advanced AI systems."},
                doc_id="doc2",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc3",
            metadata=DocMetadata(
                content={"type": "text", "text": "Bob collaborates with Alice on transformer architecture research."},
                doc_id="doc3",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
    ]
    
    # Add documents to knowledge base
    print("\nüì• Adding documents...")
    await knowledge.add_documents(documents)
    print(f"‚úÖ Added {len(documents)} documents")
    
    # Retrieve using vector search
    print("\nüîç Searching: 'Where does Alice work?'")
    results = await knowledge.retrieve(
        query="Where does Alice work?",
        limit=2,
        search_mode="vector",
    )
    
    print(f"\nüìÑ Found {len(results)} results:")
    for i, doc in enumerate(results, 1):
        print(f"\n  {i}. [Score: {doc.score:.3f}]")
        print(f"     {doc.metadata.content['text']}")


async def example_with_graph_features():
    """Example 2: Full graph features (entities + relationships)."""
    print("\n" + "="*80)
    print("Example 2: With Graph Features (Entities + Relationships)")
    print("="*80)
    
    # Initialize Neo4j graph store
    graph_store = Neo4jGraphStore(
        uri=NEO4J_URI,
        user=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database="neo4j",
        collection_name="graph_knowledge",
        dimensions=1536,
    )
    
    # Initialize knowledge base with graph features
    knowledge = GraphKnowledgeBase(
        graph_store=graph_store,
        embedding_model=DashScopeTextEmbedding(
            model_name="text-embedding-v2",
            api_key=DASHSCOPE_API_KEY,
        ),
        llm_model=DashScopeChatModel(
            model_name="qwen-max",
            api_key=DASHSCOPE_API_KEY,
            stream=False,  # Disable streaming for structured output
        ),
        enable_entity_extraction=True,
        entity_extraction_config={
            "max_entities_per_chunk": 10,
            "enable_gleanings": False,  # Disable for faster processing
        },
        enable_relationship_extraction=True,
        enable_community_detection=False,  # Disable for this example
    )
    
    # Create sample documents
    documents = [
        Document(
            id="doc4",
            metadata=DocMetadata(
                content={"type": "text", "text": "Alice works at OpenAI as a researcher specializing in language models."},
                doc_id="doc4",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc5",
            metadata=DocMetadata(
                content={"type": "text", "text": "OpenAI is located in San Francisco and develops advanced AI systems."},
                doc_id="doc5",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc6",
            metadata=DocMetadata(
                content={"type": "text", "text": "Bob collaborates with Alice on transformer architecture research."},
                doc_id="doc6",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
    ]
    
    # Add documents (will extract entities and relationships)
    print("\nüì• Adding documents (with entity/relationship extraction)...")
    await knowledge.add_documents(documents)
    print(f"‚úÖ Added {len(documents)} documents with graph features")
    
    # Test different search modes
    query = "Tell me about Alice's work"
    
    # Vector search
    print(f"\nüîç [Vector Search] Query: '{query}'")
    vector_results = await knowledge.retrieve(
        query=query,
        limit=2,
        search_mode="vector",
    )
    print(f"   Found {len(vector_results)} results")
    
    # Graph search
    print(f"\nüîç [Graph Search] Query: '{query}'")
    graph_results = await knowledge.retrieve(
        query=query,
        limit=2,
        search_mode="graph",
        max_hops=2,
    )
    print(f"   Found {len(graph_results)} results")
    
    # Hybrid search (recommended)
    print(f"\nüîç [Hybrid Search] Query: '{query}'")
    hybrid_results = await knowledge.retrieve(
        query=query,
        limit=2,
        search_mode="hybrid",
        vector_weight=0.5,
        graph_weight=0.5,
    )
    print(f"   Found {len(hybrid_results)} results")
    
    print(f"\nüìÑ Hybrid search results:")
    for i, doc in enumerate(hybrid_results, 1):
        print(f"\n  {i}. [Score: {doc.score:.3f}]")
        print(f"     {doc.metadata.content['text']}")


async def example_with_community_detection():
    """Example 3: Full features including community detection and global search."""
    print("\n" + "="*80)
    print("Example 3: Full Features (Entities + Relationships + Communities + Global Search)")
    print("="*80)
    
    # Initialize Neo4j graph store
    graph_store = Neo4jGraphStore(
        uri=NEO4J_URI,
        user=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database="neo4j",
        collection_name="full_knowledge",
        dimensions=1536,
    )
    
    # Initialize knowledge base with all features
    knowledge = GraphKnowledgeBase(
        graph_store=graph_store,
        embedding_model=DashScopeTextEmbedding(
            model_name="text-embedding-v2",
            api_key=DASHSCOPE_API_KEY,
        ),
        llm_model=DashScopeChatModel(
            model_name="qwen-max",
            api_key=DASHSCOPE_API_KEY,
            stream=False,  # Disable streaming for structured output
        ),
        enable_entity_extraction=True,
        entity_extraction_config={
            "max_entities_per_chunk": 15,
            "enable_gleanings": False,  # Disable for faster processing
            "gleanings_rounds": 1,
        },
        enable_relationship_extraction=True,
        enable_community_detection=True,  # Enable community detection
        community_algorithm="leiden",
    )
    
    # Create diverse sample documents with different relevance levels
    # This helps test the scoring algorithm's ability to distinguish quality
    documents = [
        # === HIGH RELEVANCE: Core AI research organizations and topics ===
        Document(
            id="doc7",
            metadata=DocMetadata(
                content={"type": "text", "text": "OpenAI conducts cutting-edge research in artificial intelligence, focusing on large language models, reinforcement learning, and neural network architectures like GPT-4 and transformer models."},
                doc_id="doc7",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc8",
            metadata=DocMetadata(
                content={"type": "text", "text": "Google DeepMind in London is a leading AI research laboratory that pioneered breakthroughs in deep reinforcement learning, including AlphaGo, AlphaFold, and various machine learning techniques."},
                doc_id="doc8",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc9",
            metadata=DocMetadata(
                content={"type": "text", "text": "Microsoft Research AI division collaborates with OpenAI to advance artificial intelligence research, integrating AI capabilities into Azure cloud platform and developing neural language models."},
                doc_id="doc9",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        
        # === MEDIUM RELEVANCE: Related but not core focus ===
        Document(
            id="doc10",
            metadata=DocMetadata(
                content={"type": "text", "text": "Alice works as a software engineer at a tech startup in San Francisco, where she occasionally uses machine learning libraries for data analysis tasks."},
                doc_id="doc10",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc11",
            metadata=DocMetadata(
                content={"type": "text", "text": "Bob is studying computer science at Stanford University and taking courses in algorithms, data structures, and an introductory class on artificial intelligence."},
                doc_id="doc11",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        
        # === LOW RELEVANCE: Tangentially related or different topics ===
        Document(
            id="doc12",
            metadata=DocMetadata(
                content={"type": "text", "text": "The Python programming language is widely used in software development for web applications, data analysis, and automation scripts across various industries."},
                doc_id="doc12",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc13",
            metadata=DocMetadata(
                content={"type": "text", "text": "San Francisco is a major city in California known for its Golden Gate Bridge, diverse culture, tech industry presence, and foggy weather patterns."},
                doc_id="doc13",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
        Document(
            id="doc14",
            metadata=DocMetadata(
                content={"type": "text", "text": "Cloud computing services like Azure, AWS, and Google Cloud provide scalable infrastructure for businesses to host applications, store data, and manage workloads efficiently."},
                doc_id="doc14",
                chunk_id=0,
                total_chunks=1,
            ),
        ),
    ]
    
    # Add documents (will trigger community detection in background on first call)
    print("\nüì• Adding documents (with all features)...")
    print(f"   Total documents: {len(documents)}")
    await knowledge.add_documents(documents)
    print(f"‚úÖ Added {len(documents)} documents with:")
    print("   - Entity extraction")
    print("   - Relationship extraction")
    print("   - Community detection (triggered in background)")
    
    # Wait a bit for community detection to complete
    print("\n‚è≥ Waiting for background community detection...")
    await asyncio.sleep(8)
    
    # Manually trigger community detection again to ensure it's complete
    print("\nüî¨ Running community detection...")
    try:
        result = await knowledge.detect_communities()
        print(f"‚úÖ Community detection completed:")
        print(f"   - Communities detected: {result['community_count']}")
        print(f"   - Hierarchical levels: {result['levels']}")
        print(f"   - Algorithm used: {result['algorithm']}")
        print(f"   - Status: {result.get('status', 'unknown')}")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Community detection error: {e}")
        print("   Continuing with other search modes...")
    
    # Compare different search modes
    print("\n" + "="*80)
    print("Comparing Search Modes")
    print("="*80)
    
    query = "What are the main AI research topics and organizations?"
    print(f"\nüîç Query: '{query}'")
    print("\n" + "-"*80)
    
    # 1. Vector Search
    print("\n1Ô∏è‚É£  Vector Search (baseline - pure semantic similarity)")
    try:
        vector_results = await knowledge.retrieve(
            query=query,
            limit=3,
            search_mode="vector",
        )
        print(f"   ‚úÖ Found {len(vector_results)} results")
        for i, doc in enumerate(vector_results, 1):
            print(f"   {i}. [Score: {doc.score:.3f}] {doc.metadata.content['text'][:80]}...")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    # 2. Graph Search
    print("\n2Ô∏è‚É£  Graph Search (uses entity relationships)")
    try:
        graph_results = await knowledge.retrieve(
            query=query,
            limit=3,
            search_mode="graph",
            max_hops=2,
        )
        print(f"   ‚úÖ Found {len(graph_results)} results")
        for i, doc in enumerate(graph_results, 1):
            print(f"   {i}. [Score: {doc.score:.3f}] {doc.metadata.content['text'][:80]}...")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    # 3. Hybrid Search
    print("\n3Ô∏è‚É£  Hybrid Search (vector + graph combined)")
    try:
        hybrid_results = await knowledge.retrieve(
            query=query,
            limit=3,
            search_mode="hybrid",
            vector_weight=0.5,
            graph_weight=0.5,
        )
        print(f"   ‚úÖ Found {len(hybrid_results)} results")
        for i, doc in enumerate(hybrid_results, 1):
            print(f"   {i}. [Score: {doc.score:.3f}] {doc.metadata.content['text'][:80]}...")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    # 4. Global Search (NEW - fully implemented!)
    print("\n4Ô∏è‚É£  Global Search (community-level understanding) ‚≠ê NEW")
    try:
        global_results = await knowledge.retrieve(
            query=query,
            limit=3,
            search_mode="global",
            min_community_level=0,
            max_entities_per_community=10,
            community_limit=5,
        )
        print(f"   ‚úÖ Found {len(global_results)} results")
        for i, doc in enumerate(global_results, 1):
            print(f"   {i}. [Score: {doc.score:.3f}] {doc.metadata.content['text'][:80]}...")
        
        # Show detailed results for global search
        if global_results:
            print("\nüìÑ Global Search - Detailed Results:")
            for i, doc in enumerate(global_results, 1):
                print(f"\n  {i}. Score: {doc.score:.4f}")
                print(f"     Content: {doc.metadata.content['text']}")
    except ValueError as e:
        print(f"   ‚ö†Ô∏è  {e}")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*80)
    print("üí° Search Mode Recommendations:")
    print("   - Use 'vector' for simple semantic search (fastest)")
    print("   - Use 'graph' when relationships matter (entity-centric)")
    print("   - Use 'hybrid' for best overall quality (recommended)")
    print("   - Use 'global' for thematic/overview questions (slowest, most comprehensive)")
    print("="*80)


async def main():
    """Run all examples."""
    print("\n" + "="*80)
    print("GraphKnowledgeBase Usage Examples")
    print("="*80)
    print("\nüìå ÈÖçÁΩÆ‰ø°ÊÅØ:")
    print(f"   - Neo4j URI: {NEO4J_URI}")
    print(f"   - Neo4j User: {NEO4J_USER}")
    print(f"   - DashScope API Key: {os.environ['DASHSCOPE_API_KEY'][:20]}...")
    print("\n‚ö†Ô∏è  ËØ∑Á°Æ‰øù:")
    print("   1. Neo4j Ê≠£Âú®ËøêË°å")
    print("   2. ‰øÆÊîπ‰∫ÜËÑöÊú¨‰∏≠ÁöÑ NEO4J_PASSWORD")
    
    try:
        # Á§∫‰æã 1: Âü∫Á°ÄÂêëÈáèÊ£ÄÁ¥¢
        await example_basic_vector_only()
        
        # ËØ¢ÈóÆÊòØÂê¶ÁªßÁª≠
        print("\n" + "="*80)
        user_input = input("\nÁªßÁª≠ËøêË°åÁ§∫‰æã2ÔºàÂÆû‰ΩìÊèêÂèñÔºâÂêó? (y/n): ")
        if user_input.lower() == 'y':
            await example_with_graph_features()
        
        # ËØ¢ÈóÆÊòØÂê¶ËøêË°åÁ§æÂå∫Ê£ÄÊµã
        print("\n" + "="*80)
        user_input = input("\nÁªßÁª≠ËøêË°åÁ§∫‰æã3ÔºàÁ§æÂå∫Ê£ÄÊµãÔºâÂêó? (ÈúÄË¶ÅGDSÊèí‰ª∂) (y/n): ")
        if user_input.lower() == 'y':
            await example_with_community_detection()
        
        print("\n" + "="*80)
        print("‚úÖ ÊâÄÊúâÁ§∫‰æãËøêË°åÂÆåÊàêÔºÅ")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

