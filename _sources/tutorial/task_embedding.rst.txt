
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/task_embedding.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorial_task_embedding.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_task_embedding.py:


.. _embedding:

Embedding
=========================

In AgentScope, the embedding module provides a unified interface for vector representation generation, which features:

- Support **caching embeddings** to avoid redundant API calls
- Support **multiple embedding providers** with a consistent API

AgentScope has built-in embedding classes for the following API providers:

.. list-table::
    :header-rows: 1

    * - Provider
      - Class
    * - OpenAI
      - ``OpenAITextEmbedding``
    * - Gemini
      - ``GeminiTextEmbedding``
    * - DashScope
      - ``DashScopeTextEmbedding``, ``DashScopeMultiModalEmbedding``
    * - Ollama
      - ``OllamaTextEmbedding``

All classes inherit from ``EmbeddingModelBase``, implementing the ``__call__`` method and generating ``EmbeddingResponse`` object with the embeddings and usage information.
The ``DashScopeMultiModalEmbedding`` supports multi-modal embeddings for text, images, and videos.

Taking the DashScope embedding class as an example, you can use it as follows:

.. GENERATED FROM PYTHON SOURCE LINES 34-67

.. code-block:: Python


    import asyncio
    import os
    import tempfile

    from agentscope.embedding import DashScopeTextEmbedding, FileEmbeddingCache


    async def example_dashscope_embedding() -> None:
        """Example usage of DashScope text embedding."""
        texts = [
            "What is the capital of France?",
            "Paris is the capital city of France.",
        ]

        # Initialize the DashScope text embedding instance
        embedding_model = DashScopeTextEmbedding(
            model_name="text-embedding-v2",
            api_key=os.getenv("DASHSCOPE_API_KEY"),
        )

        # Get the embedding from the model
        response = await embedding_model(texts)

        print("The embedding ID: ", response.id)
        print("The embedding create at: ", response.created_at)
        print("The embedding usage: ", response.usage)
        print("The embedding:")
        print(response.embeddings)


    asyncio.run(example_dashscope_embedding())



.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/home/runner/work/agentscope/agentscope/docs/tutorial/en/src/task_embedding.py", line 65, in <module>
        asyncio.run(example_dashscope_embedding())
      File "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/asyncio/runners.py", line 44, in run
        return loop.run_until_complete(main)
      File "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
        return future.result()
      File "/home/runner/work/agentscope/agentscope/docs/tutorial/en/src/task_embedding.py", line 56, in example_dashscope_embedding
        response = await embedding_model(texts)
      File "/home/runner/work/agentscope/agentscope/src/agentscope/embedding/_dashscope_embedding.py", line 153, in __call__
        res = await self._call_api(batch_kwargs)
      File "/home/runner/work/agentscope/agentscope/src/agentscope/embedding/_dashscope_embedding.py", line 87, in _call_api
        raise RuntimeError(
    RuntimeError: Failed to get embedding from DashScope API: {"status_code": 401, "request_id": "c5127ba0-7ebe-41c2-8426-c6052af69fd1", "code": "InvalidApiKey", "message": "No API-key provided.", "output": null, "usage": null}




.. GENERATED FROM PYTHON SOURCE LINES 68-81

You can customize your embedding model by subclassing ``EmbeddingModelBase`` and implementing the ``__call__`` method.

Embedding Cache
---------------------
AgentScope provides a base class ``EmbeddingCacheBase`` for caching embeddings, as well as a file-based implementation ``FileEmbeddingCache``.
It works as follows in the embedding module:

.. image:: ../../_static/images/embedding_cache.png
  :align: center
  :width: 90%

To use caching, just pass an instance of ``FileEmbeddingCache`` (or your custom cache) to the embedding model's constructor as follows:


.. GENERATED FROM PYTHON SOURCE LINES 81-133

.. code-block:: Python



    async def example_embedding_cache() -> None:
        """Demonstrate embedding with cache functionality."""
        # Example texts
        texts = [
            "What is the capital of France?",
            "Paris is the capital city of France.",
        ]

        # Create a temporary directory for cache demonstration
        # In real applications, you might want to use a persistent directory
        cache_dir = tempfile.mkdtemp(prefix="embedding_cache_")
        print(f"Using cache directory: {cache_dir}")

        # Initialize the embedding model with cache
        # We limit the cache to 100 files and 10MB for demonstration purposes
        embedder = DashScopeTextEmbedding(
            model_name="text-embedding-v3",
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            embedding_cache=FileEmbeddingCache(
                cache_dir=cache_dir,
                max_file_number=100,
                max_cache_size=10,  # Maximum cache size in MB
            ),
        )

        # First call - will fetch from API and store in cache
        print("\n=== First API Call (No Cache Hit) ===")
        start_time = asyncio.get_event_loop().time()
        response1 = await embedder(texts)
        elapsed_time1 = asyncio.get_event_loop().time() - start_time
        print(f"Source: {response1.source}")  # Should be 'api'
        print(f"Time taken: {elapsed_time1:.4f} seconds")
        print(f"Tokens used: {response1.usage.tokens}")

        # Second call with the same texts - should use cache
        print("\n=== Second API Call (Cache Hit Expected) ===")
        start_time = asyncio.get_event_loop().time()
        response2 = await embedder(texts)
        elapsed_time2 = asyncio.get_event_loop().time() - start_time
        print(f"Source: {response2.source}")  # Should be 'cache'
        print(f"Time taken: {elapsed_time2:.4f} seconds")
        print(
            f"Tokens used: {response2.usage.tokens}",
        )  # Should be 0 for cached results
        print(
            f"Speed improvement: {elapsed_time1 / elapsed_time2:.1f}x faster with cache",
        )


    asyncio.run(example_embedding_cache())


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.775 seconds)


.. _sphx_glr_download_tutorial_task_embedding.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: task_embedding.ipynb <task_embedding.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: task_embedding.py <task_embedding.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: task_embedding.zip <task_embedding.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
